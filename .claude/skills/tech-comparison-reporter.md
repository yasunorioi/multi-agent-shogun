# Tech Comparison Reporter - Skill Definition

**Skill ID**: `tech-comparison-reporter`
**Category**: Research / Decision Making
**Version**: 1.0.0
**Created**: 2026-02-11

---

## Overview

複数の技術・ツール・ライブラリを体系的に比較調査し、評価表と推奨案を含むレポートを生成するパターン。技術選定の場面で、感覚ではなくデータに基づいた意思決定を支援する。

---

## Use Cases

- 新規プロジェクトの技術選定（フレームワーク、DB、通信方式等）
- 既存技術のリプレース検討
- IoT通信プロトコルの比較（MQTT vs HTTP vs CoAP等）
- CSS フレームワーク、状態管理ライブラリ等の選定

---

## Skill Input

1. **比較対象**: 2〜5件の技術/ツール名
2. **用途・文脈**: 何のために比較するか（プロジェクト要件）
3. **重視する観点**: パフォーマンス、コスト、学習コスト、エコシステム等（任意）

---

## Skill Output

1. 比較レポート（Markdownファイル）
2. 5段階評価の比較表
3. 推奨案と理由

---

## Implementation Pattern

### Step 1: 比較軸の設定

用途に応じて5〜8の比較軸を設定する。汎用的な軸：

| 比較軸 | 説明 |
|--------|------|
| 機能性 | 必要な機能をカバーしているか |
| パフォーマンス | 速度、リソース効率 |
| 学習コスト | ドキュメント充実度、学習曲線 |
| エコシステム | プラグイン、コミュニティ、サードパーティ連携 |
| 運用性 | デプロイ、モニタリング、トラブルシュート |
| コスト | ライセンス、インフラ、人件費 |
| 将来性 | 開発活発度、スター数推移、企業サポート |
| 既存資産との整合 | 現プロジェクトとの親和性 |

### Step 2: 情報収集

```
各技術について以下を調査：
1. 公式ドキュメント → 機能一覧、制約
2. GitHub → Star数、最終コミット日、Issue数、コントリビューター数
3. ベンチマーク → 公開されているパフォーマンス比較
4. Stack Overflow → 質問数（エコシステムの指標）
5. 実際のプロジェクト事例 → 本番採用実績
```

### Step 3: 5段階評価

| 評価 | 意味 |
|------|------|
| ⭐⭐⭐⭐⭐ (5) | 最優秀。要件を完全に満たし、追加のメリットがある |
| ⭐⭐⭐⭐ (4) | 優秀。要件を十分に満たす |
| ⭐⭐⭐ (3) | 普通。要件は満たすが特筆すべき点はない |
| ⭐⭐ (2) | やや不足。一部要件を満たさない、または制約がある |
| ⭐ (1) | 不適。要件を満たさない、または重大な問題がある |

### Step 4: レポート生成

```markdown
# 技術比較レポート: {テーマ}

## 概要
{何を、なぜ比較するか}

## 比較対象
| 技術 | バージョン | ライセンス | GitHub Stars |
|------|-----------|-----------|-------------|
| A    | v3.2      | MIT       | 45,000      |
| B    | v2.1      | Apache    | 32,000      |
| C    | v1.8      | GPL       | 18,000      |

## 比較表

| 比較軸 | 重み | 技術A | 技術B | 技術C |
|--------|------|-------|-------|-------|
| 機能性 | ×2 | ⭐⭐⭐⭐⭐ (10) | ⭐⭐⭐⭐ (8) | ⭐⭐⭐ (6) |
| パフォーマンス | ×1.5 | ⭐⭐⭐ (4.5) | ⭐⭐⭐⭐⭐ (7.5) | ⭐⭐⭐⭐ (6) |
| 学習コスト | ×1 | ⭐⭐⭐⭐ (4) | ⭐⭐⭐ (3) | ⭐⭐⭐⭐⭐ (5) |
| エコシステム | ×1 | ⭐⭐⭐⭐⭐ (5) | ⭐⭐⭐⭐ (4) | ⭐⭐ (2) |
| 運用性 | ×1 | ⭐⭐⭐⭐ (4) | ⭐⭐⭐⭐ (4) | ⭐⭐⭐ (3) |
| コスト | ×1 | ⭐⭐⭐⭐⭐ (5) | ⭐⭐⭐⭐ (4) | ⭐⭐⭐⭐⭐ (5) |
| **合計** | | **32.5** | **30.5** | **27** |

## 各技術の詳細分析

### 技術A
**強み**: ...
**弱み**: ...
**設定例**:
```yaml
# 基本設定例
```

### 技術B
...

### 技術C
...

## 推奨案

### 第1推奨: 技術A
**理由**:
1. ...
2. ...
3. ...

### 次点: 技術B（条件付き推奨）
**採用条件**: ...の場合はBが有利

## 結論
{1-2文で最終推奨をまとめる}
```

---

## Best Practices

### 1. 重み付けの透明性
- なぜその重みにしたかを明記する
- プロジェクト要件に基づいて重みを設定（全部均等は避ける）

### 2. 設定例の提供
- 各技術の基本設定例を含める（読者がすぐ試せるように）
- 現プロジェクトの文脈に合わせた設定例

### 3. バイアスの排除
- 「以前使ったことがある」は評価軸に入れない
- 公式ドキュメントとベンチマークデータに基づく

### 4. 実績ベースの評価
- 「理論上は優れている」より「本番で使われている」を重視
- GitHub Stars だけでなく、直近のコミット頻度も見る

---

## Common Pitfalls

### 1. 比較軸の偏り
**問題**: パフォーマンスだけで選んでエコシステムが貧弱
**解決**: 最低5軸で評価、運用面も必ず含める

### 2. 古い情報での判断
**問題**: 2年前のベンチマーク記事で評価
**解決**: 公式リリースノート + 直近6ヶ月のGitHub活動を確認

### 3. 「全部入り」の推奨
**問題**: 「場合によってAもBも使い分ける」は意思決定の放棄
**解決**: 明確に1つを推奨し、次点を条件付きで示す

---

**Skill Author**: 足軽2号提案 / 将軍承認
**Last Updated**: 2026-02-11
